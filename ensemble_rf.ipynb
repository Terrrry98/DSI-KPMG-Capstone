{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e94189d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import concat\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.signal import argrelextrema\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f33a3399",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRF():\n",
    "    \n",
    "    '''\n",
    "    Vector Autoregression model\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.data_backup: dataframe, a backup copy of the input dataset\n",
    "    self.data: dataframe, the main dataset worked on\n",
    "    self.n: int, length (unit in months) of target to predict\n",
    "    self.df_result: dataframe, stores the predicted target and the true target\n",
    "    self.lag: int, number of past months used to predict the target\n",
    "    self.rmse: rounded RMSE of the prediction\n",
    "    self.target: str, name of target variable\n",
    "    self.model: record a CNN trained model\n",
    "    self.train_result: record model fit result loss\n",
    "    \n",
    "    Params\n",
    "    ----------\n",
    "    data_name: str, name of the dataset. Notice the input dataset must contain a column named 'Date'\n",
    "    target_name: str, name of target variable\n",
    "    drop_cols: list of strings, names of columns to drop\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self, data_name, target_name, drop_cols=['Date']):   \n",
    "        #import data\n",
    "        curr_path = os.getcwd()\n",
    "        input_path = os.path.join(curr_path, data_name)\n",
    "        data = pd.read_excel(input_path, index_col=0)\n",
    "        \n",
    "        #drop columns and na\n",
    "        data.drop(drop_cols, axis=1, inplace=True)\n",
    "        data.dropna(inplace = True)\n",
    "        # data.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        #set attributes\n",
    "        self.data = data\n",
    " \n",
    "        self.n = 0\n",
    "        self.df_result = 0\n",
    "        self.lag = 0\n",
    "        self.rmse = 0\n",
    "        self.target = target_name\n",
    "        self.n_features = len(data.columns) - 1\n",
    "        self.model = 0\n",
    "        self.train_result = 0\n",
    "\n",
    "    def preprocess(self, dataset):\n",
    "        ilocs_min = argrelextrema(dataset['SP500-EPS-Index'].values, np.less_equal, mode = 'wrap', order = 12)[0]\n",
    "        ilocs_max = argrelextrema(dataset['SP500-EPS-Index'].values, np.greater_equal, mode = 'wrap', order = 12)[0]\n",
    "        \n",
    "        # encode expanding period as 1, contracting period as 0\n",
    "        is_expanding = []\n",
    "        i = 0\n",
    "        is_expanding.extend(np.repeat(0, ilocs_min[i]))\n",
    "\n",
    "        while i < len(ilocs_min) - 1:\n",
    "            num_expanding = ilocs_max[i] - ilocs_min[i]\n",
    "            num_contracting = ilocs_min[i + 1] - ilocs_max[i]\n",
    "            is_expanding.extend(np.repeat(1, num_expanding))\n",
    "            is_expanding.extend(np.repeat(0, num_contracting))\n",
    "            i += 1\n",
    "\n",
    "        is_expanding.extend(np.repeat(1, ilocs_max[i] - ilocs_min[i]))\n",
    "        is_expanding.extend(np.repeat(0, dataset.shape[0] - ilocs_max[i]))\n",
    "        dataset.insert(0, 'IsExpanding', is_expanding)\n",
    "        return dataset\n",
    "    \n",
    "    def print_date_range(self):\n",
    "        #Print Range of Date column\n",
    "        print('Date Range: ', self.data_backup['Date'].iloc[0], '--', self.data_backup['Date'].iloc[-1])\n",
    "    \n",
    "    # convert series to supervised learning\n",
    "\n",
    "    \n",
    "    \n",
    "    def series_to_supervised(self, data, n_in=1, n_out=1, dropnan=True, if_target=True):\n",
    "        n_vars = 1 if type(data) is list else data.shape[1]\n",
    "        df = pd.DataFrame(data)\n",
    "        df_without_target = df.loc[:, df.columns[1:]]\n",
    "        cols, names = list(), list()\n",
    "        if if_target:\n",
    "            for i in range(n_in, 0, -1):\n",
    "                cols.append(df.shift(i))\n",
    "                names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "            for i in range(0, n_out):\n",
    "                cols.append(df.shift(-i))\n",
    "                if i == 0:\n",
    "                    names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "                else:\n",
    "                    names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "            agg = concat(cols, axis=1)\n",
    "            agg.columns = names\n",
    "        else:\n",
    "            for i in range(n_in, 0, -1):\n",
    "                cols.append(df_without_target.shift(i))\n",
    "                names += [('var%d(t-%d)' % (j+1, i)) for j in range(1, n_vars)]\n",
    "            for i in range(0, n_out):\n",
    "                cols.append(df.shift(-i))\n",
    "                if i == 0:\n",
    "                    names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "                else:\n",
    "                    names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "            agg = concat(cols, axis=1)\n",
    "            agg.columns = names\n",
    "        if dropnan:\n",
    "            agg.dropna(inplace=True)\n",
    "        return agg\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def run(self, timearray, lags=[], leads=[]):\n",
    "        ''' Run CNN\n",
    "        \n",
    "        Params\n",
    "        ----------\n",
    "        pred_begin_date: date, the begin date of prediction\n",
    "        n: int, length of prediction (unit in months)      \n",
    "        lag: int, num of past months to consider\n",
    "        if_target: boolean, whether to include target as a predictor\n",
    "        '''\n",
    "        pred_y_list = []\n",
    "        true_y_list = []\n",
    "        n = 1\n",
    "        \n",
    "        \n",
    "        self.data = self.preprocess(self.data)\n",
    "        self.data.drop('SP500-EPS-Index', axis=1, inplace=True)\n",
    "        self.data.dropna(inplace = True)\n",
    "        \n",
    "        for i in range(len(timearray)):\n",
    "            pred_begin_date = timearray[i]\n",
    "            lag = lags[i]\n",
    "            lead = leads[i]\n",
    "            # flatten data\n",
    "            reframed = self.series_to_supervised(self.data, lag, lead, True, False)\n",
    "            # drop columns we don't want to predict\n",
    "            reframed.drop(reframed.columns[range(reframed.shape[1] - self.n_features, reframed.shape[1])], axis=1, inplace=True)\n",
    "            reframed.drop(reframed.columns[range(reframed.shape[1]-1-(self.n_features+1)*(lead-1), reframed.shape[1]-1)], axis=1, inplace=True)\n",
    "            #print(reframed.columns)\n",
    "\n",
    "            values = reframed.values\n",
    "            self.n = n\n",
    "\n",
    "            test_date_begin = self.data.index.get_loc(pred_begin_date) - lag - lead + 1\n",
    "\n",
    "            train = values[:test_date_begin, :]\n",
    "            test = values[test_date_begin: test_date_begin+self.n, :]\n",
    "\n",
    "\n",
    "            # split into input and outputs\n",
    "            train_X, train_y = train[:, :-1], train[:, -1]\n",
    "            test_X, test_y = test[:, :-1], test[:, -1]\n",
    "            # reshape input to be 3D [samples, timesteps, features]\n",
    "            #train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "            #test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "            #print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "            # create and fit the LSTM network\n",
    "            model = RandomForestClassifier(max_depth=5)\n",
    "\n",
    "            result = model.fit(train_X, train_y)\n",
    "            self.model = model\n",
    "            self.train_result = result\n",
    "\n",
    "            pred_y = self.model.predict(test_X)\n",
    "\n",
    "            # reverse standardization\n",
    "            #test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "            # invert scaling for forecast\n",
    "            #test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "            #pred_y = pred_y.reshape((len(pred_y), 1))\n",
    "\n",
    "            # invert scaling for actual\n",
    "\n",
    "            #test_y = test_y.reshape((len(test_y), 1))\n",
    "\n",
    "            pred_y_list.extend(pred_y)\n",
    "            true_y_list.extend(test_y)\n",
    "        \n",
    "        print(pred_y_list)\n",
    "        print(true_y_list)\n",
    "        df_result = pd.DataFrame(pred_y_list, columns=[self.target + '_pred'])\n",
    "        df_result[self.target] = true_y_list\n",
    "        df_result['Date'] = timearray\n",
    "        df_result.set_index(['Date'],inplace=True)\n",
    "        self.df_result=df_result\n",
    "\n",
    "        \n",
    "        \n",
    "        #####################\n",
    "        #self.train_X = train_X\n",
    "        #self.train_y = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c63aac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "d = np.arange ('2008-05', '2010-05', np.timedelta64 (1,'M'), dtype='datetime64')\n",
    "d=d.astype('datetime64[D]')\n",
    "lags = [24]*24\n",
    "leads = range(1,len(d)+1)\n",
    "rf_model = AutoRF(data_name='data_1107.xlsx', target_name='SP500-EPS-Index', drop_cols=[])\n",
    "rf_model.run(timearray=d, lags=lags, leads=leads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
